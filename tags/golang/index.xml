<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>golang on Yingchi Blog</title>
    <link>https://blog.yingchi.io/tags/golang.html</link>
    <description>Recent content in golang on Yingchi Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>© 2021 Joey.Jiang</copyright>
    <lastBuildDate>Sat, 15 Aug 2020 14:21:43 +0800</lastBuildDate>
    
	<atom:link href="https://blog.yingchi.io/tags/golang/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>理解 Golang Context 机制</title>
      <link>https://blog.yingchi.io/posts/2020/8/go-context.html</link>
      <pubDate>Sat, 15 Aug 2020 14:21:43 +0800</pubDate>
      
      <guid>https://blog.yingchi.io/posts/2020/8/go-context.html</guid>
      <description>&lt;p&gt;在使用 Golang 的一些框架的时候，比如 Gin，每一个请求的 Handler 方法总是需要传递进去一个 &lt;strong&gt;context&lt;/strong&gt; 对象，然后很多请求数据，比如请求参数，路径变量等都可以从中读出来，其实在这个使用过程中已经大体理解了这个 context 是个什么东西，但是对于其中的一些细节包括具体的使用方式还是缺乏了解，因此本文就针对 golang 里面的 context 概念进行简单的探讨。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>浅析并发模型：共享内存/Actor/CSP</title>
      <link>https://blog.yingchi.io/posts/2020/6/concurrent-pattern.html</link>
      <pubDate>Thu, 25 Jun 2020 17:42:29 +0800</pubDate>
      
      <guid>https://blog.yingchi.io/posts/2020/6/concurrent-pattern.html</guid>
      <description>Golang 编程中，涉及到并发问题时，通常有以下两种解决方案：
 采用共享内存模型，利用 sync.Mutex / sync.RWMutex 等加锁、设置临界区解决数据并发访问问题； 采用消息通信模型，利用 channel 进行 goroutine 间通信，避开内存共享来解决。  官方推荐大家采用第二种方案，那么它究竟好在哪里呢？
共享内存模型 所谓共享内存模型，就是我们在并发编程的时候，通过让多个并发执行实体（线程/Go程/协程/&amp;hellip;）去操作同一个共享变量，从而达到通信的目的。
比如下面这个 Go 程序例子，全局变量 count 初始值 10000，然后开启 10000 个 Goroutine 去分别执行一次取 count 并 -1 的操作。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;sync&amp;#34; ) var ( count = 10000 wg sync.WaitGroup ) func buy() { defer wg.Done() countReplica := count count = countReplica - 1 } func main() { for i := 0; i &amp;lt; 10000; i++ { wg.</description>
    </item>
    
    <item>
      <title>Goroutine 并发模型</title>
      <link>https://blog.yingchi.io/posts/2020/3/go-goroutine.html</link>
      <pubDate>Sat, 14 Mar 2020 11:53:31 +0800</pubDate>
      
      <guid>https://blog.yingchi.io/posts/2020/3/go-goroutine.html</guid>
      <description>并发基础 在学习 Goroutine 之前，如果对于 Linux 基本的并发模型不了解，那么可能会学的一头雾水，所以一切的一切之前，从 Linux 基本的并发知识说起，复习一下。
并发与并行  并发（Concurrency）：指宏观上看起来两个程序在同时运行，比如说在单核cpu上的多任务。但是从微观上看两个程序的指令是交织着运行的，你的指令之间穿插着我的指令，我的指令之间穿插着你的，在单个周期内只运行了一个指令。这种并发并不能提高计算机的性能，只能提高效率； 并行（Parallelism）：提到并行时往往涉及到的概念就是分布式/多核/多机这种概念，即一定是指严格物理意义上的同时运行，比如多核cpu，两个程序分别运行在两个核上，两者之间互不影响，单个周期内每个程序都运行了自己的指令，也就是运行了两条指令。这样说来并行的确提高了计算机的效率。所以现在的cpu都是往多核方面发展。  进程与线程   定位：进程是资源分配的最小单位，线程是CPU调度的最小单位；
  线程依赖于进程而存在，一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程；
  进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存资源；
  创建和撤销开销： 进程的创建和撤销操作开销远大于线程创建和撤销的开销（系统都要为进程分配或回收资源，如内存空间等）；
  切换开销：进程切换时，涉及到整个当前进程 CPU 环境的保存以及新被调度运行的进程的 CPU 环境的设置。而线程切换只须保存和设置少量寄存器的内容，并不涉及存储器管理方面的操作。即，进程切换的开销也远大于线程切换的开销；
  通信：由于同一进程中的多个线程具有相同的地址空间，使它们之间的同步和通信的实现比较容易。进程间通信则是通过诸如管道、共享内存、信号、信号量、Socket、消息队列等实现；
  进程编程调试简单可靠性高，但是创建销毁开销大；线程正相反，开销小，切换速度快，但是编程调试相对复杂；
  进程间不会相互影响 ；线程一个线程挂掉将导致整个进程挂掉；
  进程适应于多核、多机分布；线程适用于多核；
  系统调用 &amp;amp; 用户态内核态 &amp;amp; 进程切换/调度 用户进程生存在用户空间中，无法直接操纵计算机的硬件，但是内核空间中的内核是可以做到的，因此内核会暴露出一些接口供用户进程使用，用户进程通过这些接口去使用内核的功能，进而操控计算机的硬件，这个用户空间与内核空间之间的桥梁，就叫做“系统调用(System call)”，与普通程序函数不同的是，内核调用会导致内核空间的数据存取和指令的执行，而普通函数只在用户空间中起作用，如果普通函数需要对内核空间进行访问，也是借助于系统调用相关函数实现的。
然后说，用户态和内核态，这是为了保证操作系统安全而建立的一个特性，大部分时间里 CPU 处于用户态，此时 CPU 只能对用户空间进行访问，用户态下的用户进程是不允许访问内核空间的，当用户进程发出系统调用的时候，内核会把 CPU 从用户态切换到内核态，然后执行相关的内核函数，执行完毕后切换回用户态，并把执行结果返回给用户。
最后说到进程，为了实现一开始说的操作系统并发特性，Linux 操作系统可以凭借 CPU 的强大性能在多个进程之间快速切换，这个过程从专业上讲我们称为进程间的上下文切换，通过这种快速的切换，营造了多个进程同时运行的假象，而每个进程也地以为自己独占 CPU，但是我们要知道的是，同一时刻正在运行的进程仅会有一个。最重要的是，进程的切换是需要付出代价的，就像一开始提到的，进程切换时，涉及到整个当前进程 CPU 环境的保存以及新被调度运行的进程的 CPU 环境的设置，即进程切换的开销是比较大的。此外，除了进程切换，为了使每个生存的进程都有运行的机会，内核还要考虑下次切换时运行哪个进程，何时进行切换，被换下的进程何时重新换上，这些类似的问题称为进程调度。</description>
    </item>
    
    <item>
      <title>哈希表原理 &amp; Go Map 实现</title>
      <link>https://blog.yingchi.io/posts/2020/3/go-map.html</link>
      <pubDate>Tue, 10 Mar 2020 11:23:08 +0800</pubDate>
      
      <guid>https://blog.yingchi.io/posts/2020/3/go-map.html</guid>
      <description>Go Map 也就是所谓的“ HashTable ”数据结构，有些语言，比如 Python 中称作“字典”，但是无论如何都是一种东西。 HashTable 最重要的特点是：
 提供键值对形式的的存储结构，即提供键值之间的映射； 具有O(1)的读写性能  HashTable 的思想很简单，但是实现原理思路在不同的语言中都有着些许不同，本文主要针对 Go Map 这种 HashTable 的实现和相关问题展开讨论。
基本原理 在讨论 Go 的 Map 之前，首先要熟悉 HashTable 的基本原理，当然这些都是上个世纪的知识点了，但是还是有必要深入理解透彻的。
HashTable 的两个主要概念涉及到：Hash Function 和 冲突处理。
Hash Function 前面说过 Hash Table 是存储键值对的数据结构，所以容易理解，所谓 Hash Function 就是将 key 映射到某个存储位置的函数。
Hash Function 的选择非常重要，好的 Hash Function 可以确保 Hash 结果尽可能的均匀，最理想的情况是每一个不同的 key 都能映射到一个独立的存储索引位置上，但是，毕竟，这只是理想。
比较实际的思想还是让 Hash Function 的结果能够尽可能的均匀分布即可，既然是尽可能均匀分布，那么就有冲突的风险，冲突很好理解：
比如有个 Hash Function 是 key %3，那么对 key = 1/4/7 执行 hash 结果就是：</description>
    </item>
    
    <item>
      <title>Go Array 与 Slice 原理</title>
      <link>https://blog.yingchi.io/posts/2020/3/go-array-slice.html</link>
      <pubDate>Thu, 05 Mar 2020 19:42:31 +0800</pubDate>
      
      <guid>https://blog.yingchi.io/posts/2020/3/go-array-slice.html</guid>
      <description>数组 Array 几乎每个常见的编程语言都有数组这个概念，但是每个语言对于数组的定位都不一样，有的语言会把数组用作常用的基本的数据结构，比如 JavaScript，而 Golang 中的数组(Array)，更倾向定位于一种底层的数据结构，记录的是一段连续的内存空间数据。但是在 Go 语言中平时直接用数组的时候不多，大多数场景下我们都会直接选用更加灵活的切片(Slice)，我这里很谨慎地说“直接”用数组，因为里面有学问，稍后会说。在Go程序中经常看不到数组的一个很重要原因是，数组的大小是固定的&amp;hellip; ，所以很多场景下我们无法直接给出数组的确定长度，因此才会选择长度“可变”的切片。变与不变是编程中一个恒久远的话题，牵扯到这个话题的往往是性能与灵活性两个关键词，这个话题很庞大，有机会会单独写一篇博客进行探讨。
回到数组中，数组的声明形式：
var arr [5]int var buffer [256]byte 初始化方式有两种，一种是显示声明长度，另一种是[...]T推断长度，注意，推断长度也是给出了长度，这个和之后 Slice 的[]T的声明方式是不一样的：
arr1 := [3]int{0,1,2} arr2 := [...]string{&amp;#34;Joey&amp;#34;,&amp;#34;Sophie&amp;#34;} 第二种初始化属于语法糖，会经过编译器推导，得到数组长度，即最终转换成第一种，显然，两种方式在运行时是没有任何区别的。但是在编译期，Go 为不同类型不同结构的初始化方式进行了优化（不止是数组的初始化这一点上，其它一些代码同样如此），对于优化过程，可以简单概括为下面的话：
 如果数组中元素的个数小于或者等于 4 个，那么所有的变量会直接在栈上初始化； 如果数组元素大于 4 个，变量就会在静态存储区初始化然后拷贝到栈上，这些转换后的代码才会继续进入中间代码生成和机器码生成两个阶段，最后生成可以执行的二进制文件。  数组虽然比较重要，但是的概念其实比较简单，还有一个非常需要注意的点是，当你用到 Go 数组的时候，一定要注意一个避不开的问题，一定不要越界访问
切片 Slice 及其与 Array 的关系 刚接触 Go 的一些学习者们肯定会混淆 Array 与 Slice 的用法，我想主要原因是受其它语言影响比较大，比如国内用 Java 的比较多，如果突然换到 Go，一定会对这个 slice 概念一头雾水。
很多人仅仅知道 Slice 与 Array 的区别是：Slice 长度可变，如果仅仅是知道这个的话其实是很危险的，平时有一些错误的用法会直接把你整的找不着北，我们需要从底层了解这个语言特性。
学习 slice，或者说区别 Slice 与 Array 的首要关键是记住下面几点：
 Slice 不是 Array，它描述一个 Array； Slice 的本质是一个 Struct，携带一个数组指针，长度，容量，这是他长度可变的根本原因；  可以在 Go 源码中找到 sliceHeader 的定义：</description>
    </item>
    
  </channel>
</rss>