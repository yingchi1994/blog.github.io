<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>network on Yingchi Blog</title>
    <link>https://blog.yingchi.io/tags/network.html</link>
    <description>Recent content in network on Yingchi Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>© 2021 Joey.Jiang</copyright>
    <lastBuildDate>Mon, 13 Apr 2020 20:26:41 +0800</lastBuildDate>
    
	<atom:link href="https://blog.yingchi.io/tags/network/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Kubernetes &amp; Docker 网络原理（三）</title>
      <link>https://blog.yingchi.io/posts/2020/4/docker-k8s-network-3.html</link>
      <pubDate>Mon, 13 Apr 2020 20:26:41 +0800</pubDate>
      
      <guid>https://blog.yingchi.io/posts/2020/4/docker-k8s-network-3.html</guid>
      <description>Service 通信 kube-proxy 运行机制 为了支持集群的水平扩展、高可用性，Kubernetes抽象出了Service的概念。Service是对一组Pod的抽象，它会根据访问策略（如负载均衡策略）来访问这组Pod。 Kubernetes在创建服务时会为服务分配一个虚拟的IP地址，客户端通过访问这个虚拟的IP地址来访问服务，服务则负责将请求转发到后端的Pod上。起到一个类似于反向代理的作用，但是它和普通的反向代理还是有一些不同：首先，它的Service 的 IP 地址，也就是所谓的 ClusterIP 是虚拟的，想从外面访问还需要一些技巧；其次，它的部署和启停是由Kubernetes统一自动管理的。
Service 和 Pod 一样，其实仅仅是一个抽象的概念，背后的运作机制是依赖于 kube-proxy 组件实现的。
在 Kubernetes 集群的每个 Node 上都会运行一个 kube-proxy 服务进程，我们可以把这个进程看作 Service 的透明代理兼负载均衡器，其核心功能是将到某个 Service 的访问请求转发到后端的多个 Pod 实例上。此外，Service的Cluster IP与 NodePort 等概念是 kube-proxy 服务通过iptables的NAT转换实现的，kube-proxy 在运行过程中动态创建与 Service 相关的 iptables 规则，这些规则实现了将访问服务（Cluster IP或NodePort）的请求负载分发到后端 Pod 的功能。由于 iptables 机制针对的是本地的 kube-proxy 端口，所以在每个 Node 上都要运行 kube-proxy 组件，这样一来，在 Kubernetes 集群内部，我们可以在任意 Node 上发起对 Service 的访问请求。综上所述，由于 kube-proxy 的作用，在 Service 的调用过程中客户端无须关心后端有几个 Pod，中间过程的通信、负载均衡及故障恢复都是透明的。
kube-proxy 运行模式 kube-proxy 的具体运行模式其实是随着 Kubernetes 版本的演进有着较大的变化的，整体上分为以下几个模式的演化：
 userspace (用户空间代理)模式 iptables 模式 IPVS 模式  userspace 模式</description>
    </item>
    
    <item>
      <title>Kubernetes &amp; Docker 网络原理（二）</title>
      <link>https://blog.yingchi.io/posts/2020/4/docker-k8s-network-2.html</link>
      <pubDate>Sun, 12 Apr 2020 21:45:23 +0800</pubDate>
      
      <guid>https://blog.yingchi.io/posts/2020/4/docker-k8s-network-2.html</guid>
      <description>Kubernetes Pod 间通信 之前的文章中主要关于 Docker 的网络实现进行了介绍和探讨，对于 Docker 网络而言，其最大的局限性在于跨主机的容器通信方案上存在空白，而 Kubernetes 作为适合大规模分布式集群的容器编排平台，其在网络实现层面上主要解决的问题就包括了如下几点：
 容器间通信； Pod 间通信； Pod 与 Service 通信； 集群内外通信；  这篇博文主要针对 Kubernetes 的容器间通信和 Pod 间通信进行介绍和探讨，之后再通过单独一篇文章去探讨 Pod 与 Service 的通信，也就是 kube-proxy 工作原理和 Service 机制相关。
容器间通信 学习 Kubernetes 的容器间通信方案之前要理解 Kubernetes 中的 Pod 概念，Pod 是 Kubernetes 中最基本的调度单位，而不是 Docker 容器，Pod 的本意是豆荚，可以将容器理解为豆荚中的豆子，一个 Pod 可以包含多个有关联关系的容器，之后讨论的 Pod 与 Service 的通信也是从 Pod 层面而言的。这是必须要提前认识的概念，但是在底层，还是涉及到容器之间的通信，毕竟 Pod 只是一个抽象概念。
同一个 Pod 内的容器不会跨主机通信，它们共享同一个 Network Namesapce 空间，共享同一个 Linux 协议栈。所以对于网络的各类操作，因此可以把一个 Pod 视作一个独立的「主机」，内部的容器可以用 localhost 地址访问彼此的端口。这么做的结果是简单、安全和高效，也能减小将已经存在的程序从物理机或者虚拟机移植到容器下运行的难度。
如图，Node 上运行着一个 Pod 实例，Pod 内部的容器共享同一个 Network Namespace，因此容器1和容器2之间的通信非常简单，就可以通过直接的本地 IPC 方式通信，对于网络应用，可以直接通过 localhost 访问指定端口通信。因此对于一些传统程序想要移植到 Pod 中，几乎不需要做太多的修改。</description>
    </item>
    
    <item>
      <title>Kubernetes &amp; Docker 网络原理（一）</title>
      <link>https://blog.yingchi.io/posts/2020/4/docker-k8s-network-1.html</link>
      <pubDate>Sat, 11 Apr 2020 22:14:12 +0800</pubDate>
      
      <guid>https://blog.yingchi.io/posts/2020/4/docker-k8s-network-1.html</guid>
      <description>Docker 网络实现 平时在进行 Kubernetes 开发和运维的时候，接触到的最多的概念应该就是 Docker 与 Kubernetes 的网络概念了，尤其是 Kubernetes，各种各样的 IP，Port，有时候会混淆，因此有必要对 Docker 和 Kubernetes 的底层网络实现进行学习。这篇文章呢就先针对 Docker 的网络实现进行一下分析介绍。
Docker 网络基础 Docker 的网络实现主要利用到的还是 Linux 网络相关的技术，如 Network Namespace、Veth 设备对、网桥、iptables、路由。
Network Namespace 基本原理 作用可以用一句话概括：
实现 Linux 网络虚拟化，即容器间网络协议栈层面的隔离
通过 Network Namespace 技术就可以实现不同的 Docker 容器拥有自己完全隔离的网络环境，就像各自拥有自己独立的网卡一样。不同的 Network Namespace 下默认是不可以直接通信的。
Linux 的 Network Namespace 中可以有自己独立的路由表及独立的 iptables 设置来提供包转发、NAT 及 IP 包过滤等操作。为了隔离出独立的协议栈，需要纳入命名空间的元素有进程、套接字、网络设备等。进程创建的套接字必须属于某个命名空间，套接字的操作也必须在命名空间中进行。同样，网络设备也必须属于某个命名空间。因为网络设备属于公共资源，所以可以通过修改属性实现在命名空间之间移动。
Linux 的网络协议栈是非常复杂的，这里因为毕竟不是做系统底层开发，所以争取从概念层面对于 Linux 的 Network Namespace 这种网络隔离机制进行理解：
通过查阅相关书籍知道，Linux 网络协议栈为了支持 Namespace 这种隔离机制，方法就是让一些与网络协议栈相关的全局变量称为一个 Network Namespace 变量的成员，协议栈函数调用时指定 Namespace 参数，这个就是 Linux 实现 Network Namespace 的核心原理，通过这种方式，实现一些协议栈全局变量的私有化，保证有效的隔离。</description>
    </item>
    
    <item>
      <title>网络模型学习基础：各层网络设备概念</title>
      <link>https://blog.yingchi.io/posts/2019/10/network-devices.html</link>
      <pubDate>Sun, 27 Oct 2019 00:29:30 +0800</pubDate>
      
      <guid>https://blog.yingchi.io/posts/2019/10/network-devices.html</guid>
      <description>在学习研究诸如 kubernetes 网络或 Docker 网络等各种开源网络模型时，会涉及到各种或实际或虚拟的网络设备概念，例如各种虚拟网桥。因此必须对这些网络设备有充分的认识才可以进行接下来的学习。
  根据 OSI 参考模型，网络分为七层，根据之后的学习需要，这里主要针对 L1、L2、L3 层的设备进行学习认识
 L1：Hub（集线器/中继器） L1 层即“物理层”，作为网络的最底层，这一层的网络设备所做的事情比较单调，主要的作用就是实现物理上的网络连通，如下图几个终端节点，
想要实现这几个节点的互连互通，可以连接到叫做 Hub（集线器）的设备上，如下图，这个设备的主要任务仅仅是把接收到的信号整型放大，从其它各个端口转发出去，因此也称之为“中继器”。
以 Node0 为例展示一下节点发送网络信号的过程。如下图，Node0 向连接的 Hub 发出网络信号，Hub 接收到信号后，将其整型放大，然后转发给了 Node1、Node2、Node3。这其实就是最简单的一种星型的局域网架构。
这个过程要注意两点核心：
 Hub 仅仅对信号进行物理上的整型放大操作 Hub 转发时采用的是广播方式，向其它端口节点转发信号，无选择  然后我们再来看一个复杂一点的例子，假如两个机房各有一组终端节点连接到了各自的 Hub 上，各自组成了局域网，如下图。
我们现在想把两个房间的网络互连起来，应该如何做？按照上面的思想，我们是否可以加入一个更高层级的 Hub（称之为主干 Hub），把各个机房的网络连接起来？如图
答案是可行的，在这种情况下，通过中间这个主干 Hub的转发，我们可以将一个机房发出的信号转发到另一个机房，如图
但是，虽然可行，我们应该有这样的疑问，这样做真的好吗？虽然两个机房的网络互通了，但是是否又增加了这个网络的负担呢？我们举一个简单的例子就可以发现问题所在，假如 Node0 仅仅是想将信号发送给 Node1，尽管从网络拓扑中看到他们挨得很近，仅仅通过一个 Hub 就可以转发到，但是由于 Hub 只能采用广播的方式转发，因此这个信号不仅被传到了 Node2 上，还通过刚加入的总集线器被传递到了另一个机房的所有节点中，当然这些都是无用功。
说到这里，我们还要认识两个概念 —— 冲突域和广播域。其实很好理解，所谓冲突域，很多地方也叫碰撞域，顾名思义，就是在当网络中有一个信号在流转时，此时若有另一个节点向网络中发送信号，会引起干扰，也就是冲突或碰撞，这个受波及的范围就是冲突域，我们可以认为，L1 网络中靠类似 Hub 这种设备连接起来的物理网段都是属于一个冲突域，Hub 是无法隔离冲突域的，在 L2、L3 网络中均有能力隔离冲突域；另一个概念，广播域，广播域就是接收同样广播消息的集合，我们一般认为，广播域其实就是同一个网络的代名词，我们如今所使用的互联网，其实是通过 Router 这种网际交换设备连接不同网络而产生的。
结合上面这两个概念，我们重新分析通过主干 Hub 连接两个局域网的方式，就能明白为什么这样会严重影响网络性能了。
那么，还是针对连接两个机房的场景，我们期望既可以实现两个网络的互通，又能提高通信的效率，有没有好的方式呢？
L2：Bridge（网桥）、Switch(交换机/多端口网桥) 现在到网络模型的第2层，也就是数据链路层，看一下这一层的网络设备。继续讨论之前的场景，这次我们不再采用主干 Hub 的方案，而是加入一个叫做 Bridge（网桥）的设备，狭义上的网桥其实是二端口网桥，如图。所谓 Bridge，我们很容易就能明白这是一个桥接设备，桥接的核心是延长，是扩大，因此，我们可以在某种程度上把它看做为一个智能的、高级的 Hub，智能高级的原因是它是工作在第二层的，在进行它的工作原理介绍之前，重新看一下我之前 L1 层对于 Hub 工作原理的描述，网络中流转的信息我在第一层中是以“信号”称呼的，因为第一层只能操作物理电信号，无非就是对电流的整型放大复制转发。</description>
    </item>
    
  </channel>
</rss>